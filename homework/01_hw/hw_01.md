---
title: Homework 1
subtitle: Color spaces, annotations, thresholding, filters, and wavelets
downloads:
  - file: hw_01.ipynb
    title: hw_01.ipynb
  - file: homework.py
    title: homework.py
abstract: |
    This problem set deals with material from the first four lectures. 

    - You may reference any materials, but make sure if you directly copy code, that you provide a link to the source in the mark up. Likewise, if you find a really helpful website, you should add that link as well.

    - Include any additional scripts or files needed to reproduce.
---
::::{dropdown} Modules
:::{code-cell} python
import os
import cv2
import numpy as np
from matplotlib import pyplot as plt
import ipywidgets as widgets
import homework as hw # see homework.py file
import pywt
:::
::::

## Problem 1
Load the `Pitt_Cathedral.jpg` file from the `Data` folder as a color image, convert the image colors and display using the `imshow()` command, and convert to grayscale and display the image again.

:::{code} python
# read in the image
img = cv2.imread(os.path.relpath('Data/Pitt_Cathedral.jpg'), cv2.IMREAD_COLOR)

# convert to RGB
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# convert to grayscale
img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# show the results
fig, axs = plt.subplots(2, 2, figsize=(8,6), layout='constrained')
fig.suptitle('Problem 1 Solution')
axs[0,0].imshow(img); axs[0,0].set_title('BGR')
axs[0,1].imshow(img_rgb); axs[0,1].set_title('RGB')
axs[1,0].imshow(img_gray, cmap='gray', vmin=0, vmax=255); axs[1,0].set_title('Grayscale')
axs[1,1].axis('off')
plt.show()
:::

:::{figure} Data/p1_sol.jpg
:align: center
:::

## Problem 2
1. Annotate the Cathedral image from [Problem 1](#problem-1) with the slogan "Hail to Pitt" placed in the image.
2. In a different font and color, add your name in text to the same image.
3. Crop the image around the Cathedral and display the image.

:::{code} python
# create a copy of the image
img_annotated = img_rgb.copy()

# H2P text
h2p = {
    'text': 'Hail to Pitt',
    'scale': 2.3,
    'face': cv2.FONT_HERSHEY_SIMPLEX,
    'color': (0, 0, 255), # blue
    'thickness': 2,
    'origin': (325, 75),
    'lineType': cv2.LINE_AA
}

# annotate the image
cv2.putText(
    img_annotated, 
    h2p['text'],
    h2p['origin'],
    h2p['face'],
    h2p['scale'],
    h2p['color'],
    h2p['thickness'],
    h2p['lineType']
)

# Name text
name = {
    'text': 'Jacob Cunningham',
    'scale': h2p['scale'],
    'face': cv2.FONT_HERSHEY_PLAIN,
    'color': (255, 0, 0), # red
    'thickness': h2p['thickness'],
    'origin': (350, 675),
    'lineType': h2p['lineType']
}

# annotate the image
cv2.putText(
    img_annotated, 
    name['text'],
    name['origin'],
    name['face'],
    name['scale'],
    name['color'],
    name['thickness'],
    name['lineType']
)

# crop the image
img_cropped = img_annotated.copy()[0:701, 250:801]

# show the image
fig, axd = plt.subplot_mosaic([['Original', 'Cropped'], ['Annotated', 'Cropped']], figsize=(6, 4), layout='constrained')
fig.suptitle('Problem 2 Solution')
axd['Original'].imshow(img_rgb); axd['Original'].set_title('Original')
axd['Annotated'].imshow(img_annotated); axd['Annotated'].set_title('Annotated')
axd['Cropped'].imshow(img_cropped); axd['Cropped'].set_title('Cropped')
plt.show()
:::

:::{figure} Data/p2_sol.jpg
:align: center
:::

## Problem 3
1. Create a binary mask separating the blue sky by thresholding
2. Using this mask, change (just the) sky to be a deeper blue

### Preprocessing

__Get image information__

:::{code} python
# get the image size
height, width = img.shape[:2]

# convert to hsv
img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

# split the color channels
r, g, b = cv2.split(img_rgb)
h, s, v = cv2.split(img_hsv)

# plot the images and their histograms
fig, axs = plt.subplots(3, 2, figsize=(8,8), layout='constrained')
axs[0,0].imshow(img_rgb)
axs[0,0].set_title('RGB')
axs[0,1].hist(r.ravel(), bins=75, color='red', alpha=0.5, label='Red')
axs[0,1].hist(b.ravel(), bins=75, color='blue', alpha=0.5, label='Blue')
axs[0,1].hist(g.ravel(), bins=75, color='green', alpha=0.5, label='Green')
axs[0,1].legend()
axs[0,1].set_title('Image Histogram')
axs[1,0].imshow(img_rgb)
axs[1,0].set_title('HSV') # since RGB required for matplotlib
axs[1,1].hist(h.ravel(), bins=75, color='red', alpha=0.5, label='Hue')
axs[1,1].hist(s.ravel(), bins=75, color='blue', alpha=0.5, label='Saturation')
axs[1,1].hist(v.ravel(), bins=75, color='green', alpha=0.5, label='Value')
axs[1,1].legend()
axs[1,1].set_title('Image Histogram')
axs[2,0].imshow(img_gray, cmap='gray', vmin=0, vmax=255)
axs[2,0].set_title('Grayscale')
axs[2,1].hist(img_gray.ravel(), bins=75, color='gray', edgecolor='black')
axs[2,1].set_title('Image Histogram')
fig.suptitle(f'Pitt Cathedral: {width} pixels by {height} pixels')
plt.show()
:::

:::{figure} Data/p2_info.jpg
:align: center
:::

:::{note}
The grayscale image is bimodal which indicates segmentation by thresholding may be a good approach.
:::

__Various threshold techniques__

:::{code} python
# global method
val_global, img_global = cv2.threshold(img_gray, 100, 255, cv2.THRESH_BINARY)

# Otsus method
val_otsus, img_otsus = cv2.threshold(img_gray, 167, 255, cv2.THRESH_OTSU)

# adaptive thresholds
img_adpt_mean = cv2.adaptiveThreshold(img_gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 0)
img_adpt_gauss = cv2.adaptiveThreshold(img_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 9, 0)

# show the results
fig, axs = plt.subplots(2, 2, figsize=(8,6), layout='constrained')
fig.suptitle('Threshold Methods and Results')
axs[0,0].imshow(img_global, cmap='gray', vmin=0, vmax=255); axs[0,0].set_title(f'Global Threshold of {val_global:.0f}')
axs[0,1].imshow(img_otsus, cmap='gray', vmin=0, vmax=255); axs[0,1].set_title(f'Otsus Threshold of {val_otsus:.0f}')
axs[1,0].imshow(img_adpt_mean, cmap='gray', vmin=0, vmax=255); axs[1,0].set_title('Adaptive Mean')
axs[1,1].imshow(img_adpt_gauss, cmap='gray', vmin=0, vmax=255); axs[1,1].set_title('Adaptive Gaussian')
plt.show()
:::

:::{figure} Data/p2_thresh_techs.jpg
:align: center
:::

__Finetuning__

::::{tip} `finetune_threshold`
:class: dropdown
:::{code} python
# Function to load an image from a file path and interactively adjust the threshold
def finetune_threshold(image):
    """
    Takes an image (as a numpy array) and displays it with an interactive 
    thresholding widget. The user can adjust the threshold value with a slider, and 
    the binary thresholded image will be updated in real-time.

    The function provides both manual thresholding via the slider and automatically 
    displays the original image in grayscale alongside the thresholded version for comparison.

    Parameters:
    -----------
    image : numpy.ndarray
        The input image as a numpy array. The image can be either grayscale or color (RGB/BGR).
        If the image is color, it will be automatically converted to grayscale for thresholding.

    How it works:
    -------------
    - If the image is in color, it is converted to grayscale for thresholding.
    - The thresholding slider allows you to set a threshold value between 0 and 255.
    - When the slider is adjusted, a binary image is created using the selected threshold value,
      and the thresholded image is displayed next to the original image in real time.

    Slider Interaction:
    -------------------
    - The threshold slider allows dynamic adjustment of the threshold value from 0 to 255.
    - When a new threshold value is selected, the binary thresholding result is immediately 
      updated and displayed.
    
    Visualization:
    --------------
    - The function shows two images side-by-side:
      - The original image in grayscale.
      - The thresholded (binary) image where pixels are either black or white based on 
        the threshold value.

    Example:
    --------
    To use the function, pass an image as a numpy array:

        finetune_threshold(image)

    This will display the interactive thresholding interface.
    """
    # Check if the image is in color, and convert to grayscale if necessary
    if len(image.shape) == 3:  # If the image has 3 channels (assumed to be RGB or BGR)
        img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        img_gray = image

    # Convert the image to uint8 type if needed
    img_gray = np.array(img_gray, dtype=np.uint8)

    # Precompute Otsu's
    val_otsu, _ = cv2.threshold(img_gray, 127, 255, cv2.THRESH_OTSU)
    
    # Function to apply thresholding and display the result
    def apply_threshold(threshold_value):
        # Apply the threshold to the grayscale image
        _, binary_img = cv2.threshold(img_gray, threshold_value, 255, cv2.THRESH_BINARY)

        # Display the output
        fig, axs = plt.subplot_mosaic([['Gray', 'Binary'], ['Gray', 'Binary'], ['Histogram', 'Histogram']], figsize=(8, 8*2/3), layout='constrained')
        fig.suptitle('Threshold Finetuning')
        axs['Gray'].imshow(img_gray, cmap='gray', vmin=0, vmax=255)
        axs['Gray'].set_title('Grayscale')
        axs['Binary'].imshow(binary_img, cmap='gray', vmin=0, vmax=255)
        axs['Binary'].set_title(f'Threshold: {threshold_value}')
        axs['Histogram'].hist(img_gray.ravel(), bins=75, alpha=0.7, color='gray', edgecolor='black')
        axs['Histogram'].axvline(x=threshold_value, color='r', linestyle='-', linewidth=2, label=f'Threshold: {threshold_value}')
        axs['Histogram'].axvline(x=val_otsu, color='g', linestyle='--', linewidth=2, label=f'Otsu: {val_otsu:.0f}')
        axs['Histogram'].legend()
        axs['Histogram'].set_title('Image Histogram')
        plt.show()

    # Create an interactive slider widget to control the threshold value
    threshold_slider = widgets.IntSlider(
        value=167,    # Initial value
        min=0,        # Minimum threshold value
        max=255,      # Maximum threshold value
        step=1,       # Step size for the slider
        description='Threshold:',
        continuous_update=False  # Update only when the slider is released
    )

    # Use interact to link the slider with the apply_threshold function
    _ = interact(apply_threshold, threshold_value=threshold_slider)
:::
::::

After finetuning, select a threshold value.

:::{code} python
thresh_selected = 167
:::

### Processing

:::{code} python
# Make the sky darker
darker_array = np.ones(img_rgb.shape, dtype='uint8') * 120
darker_sky =  cv2.subtract(img_rgb, darker_array)

# Threshold the image based on finetuning
_, img_thresh = cv2.threshold(img_gray, thresh_selected, 255, cv2.THRESH_BINARY)

# Make the kernel, small size used to caputure fine details
kernel_size = 3
kernel = np.ones((kernel_size, kernel_size), dtype=np.uint8)

# perform opening
background_mask = cv2.morphologyEx(img_thresh, cv2.MORPH_OPEN, kernel, iterations=10)

# perform bitwise operations
foreground_mask = cv2.bitwise_not(background_mask)
new_foreground = cv2.bitwise_and(img_rgb, img_rgb, mask=foreground_mask)
new_background = cv2.bitwise_and(darker_sky, darker_sky, mask=background_mask)

# add the background and foreground
result = cv2.add(new_background, new_foreground)

# show the result
fig, axs = plt.subplots(2, 2, figsize=(8, 6), layout='constrained')
fig.suptitle('Problem 3 Solution')
axs[0,0].imshow(img_rgb); axs[0,0].set_title('Orignal')
axs[0,1].imshow(img_thresh, cmap='gray', vmin=0, vmax=255); axs[0,1].set_title(f'{thresh_selected:.0f} Global Threshold')
axs[1,0].imshow(background_mask, cmap='gray', vmin=0, vmax=255); axs[1,0].set_title('Binary Mask')
axs[1,1].imshow(result); axs[1,1].set_title('Result')
plt.show()
:::

:::{figure} Data/p3_sol.jpg
:align: center
:::

## Problem 4

Write a function to preform a median filter operation using an arbitrary kernel (taken as a second argument).  The median filter should compute the median value from the pixels in the kernel and replace the value at the kernel anchor (center).

::::{tip} `median_filter_arbitrary`
:class: dropdown
:::{code} python
def median_filter_arbitrary(image, kernel_size):
    """
    Applies a median filter to an image using an arbitrary kernel size, ensuring that the 
    kernel size is odd to have a well-defined center pixel.

    The function works on both grayscale and color images. For color images, it applies the 
    median filter independently to each color channel (Red, Green, Blue). If an even-sized 
    kernel is provided, the function raises a ValueError.

    Parameters:
    -----------
    image : numpy.ndarray
        The input image as a numpy array. The image can be either grayscale (2D array) or color (3D array).
        If the image is color, the median filter is applied separately to each channel (R, G, B).
    kernel_size : int or tuple of two ints
        The size of the kernel to be applied. If an int is provided, a square kernel of size
        (kernel_size, kernel_size) is used. If a tuple of two ints is provided, it represents the
        height and width of the kernel (kernel_height, kernel_width). Both values must be odd to have a 
        well-defined center pixel.

    How it works:
    -------------
    - For each pixel in the image, the function extracts a neighborhood defined by the kernel size.
    - It computes the median of the pixel values in the kernel and replaces the center pixel of the
      kernel with this median value.
    - The median filter is applied channel-by-channel for color images.

    Edge Handling:
    --------------
    - The function pads the image with edge values to handle pixels on the borders of the image,
      ensuring that every pixel, including border pixels, can be processed with the kernel.

    Constraints:
    ------------
    - The kernel size must be odd for both the height and width to have a well-defined center pixel.
    - If an even-sized kernel is provided, a ValueError is raised.

    Example:
    --------
    To apply a 5x5 median filter to a grayscale image:

        filtered_image = median_filter_arbitrary(image, kernel_size=5)

    To apply a 3x5 median filter to a color image:

        filtered_image = median_filter_arbitrary(image, kernel_size=(3, 5))

    Returns:
    --------
    filtered_image : numpy.ndarray
        The filtered image with the same dimensions as the input image. The image will be
        either grayscale or color, depending on the input.

    Raises:
    -------
    ValueError:
        If the kernel size provided is even (i.e., not odd for both height and width).
    """
    # Handle kernel size as either a single int or a tuple
    if isinstance(kernel_size, int):
        kernel_height, kernel_width = kernel_size, kernel_size
    elif isinstance(kernel_size, tuple) and len(kernel_size) == 2:
        kernel_height, kernel_width = kernel_size
    else:
        raise ValueError("kernel_size must be an int or a tuple of two ints (height, width).")
    
    # Ensure the kernel size is odd
    if kernel_height % 2 == 0 or kernel_width % 2 == 0:
        raise ValueError("Kernel height and width must be odd to have a well-defined center pixel.")
    
    # Padding amounts (half the kernel size on each side)
    pad_height = kernel_height // 2
    pad_width = kernel_width // 2

    # Process the image
    if len(image.shape) == 2:  # Grayscale image
        padded_image = np.pad(image, ((pad_height, pad_width)), mode='edge')
        filtered_image = np.zeros_like(image)

        for i in range(pad_height, padded_image.shape[0] - pad_height):
            for j in range(pad_width, padded_image.shape[1] - pad_width):
                kernel = padded_image[i - pad_height:i + pad_height + 1, j - pad_width:j + pad_width + 1]
                filtered_image[i - pad_height, j - pad_width] = np.median(kernel)

    elif len(image.shape) == 3:  # Color image
        rows, cols, channels = image.shape
        filtered_image = np.zeros((rows, cols, channels), dtype=np.uint8)

        for c in range(channels):
            channel = image[:, :, c]
            padded_channel = np.pad(channel, ((pad_height, pad_width)), mode='edge')
            
            # Correct the loop to stay within bounds
            for i in range(pad_height, padded_channel.shape[0] - pad_height):
                for j in range(pad_width, padded_channel.shape[1] - pad_width):
                    kernel = padded_channel[i - pad_height:i + pad_height + 1, j - pad_width:j + pad_width + 1]

                    # Make sure the indices are within bounds for the original image
                    if (i - pad_height) < filtered_image.shape[0] and (j - pad_width) < filtered_image.shape[1]:
                        filtered_image[i - pad_height, j - pad_width, c] = np.median(kernel)

    return filtered_image
:::
::::

:::{code} python
# define kernels
square_kernel = 9
kernel_width = 9
kernel_height = 13

# pass to median filter
img_median_filter_square = hw.median_filter_arbitrary(img_rgb, square_kernel)
img_median_filter_rect = hw.median_filter_arbitrary(img_rgb, (kernel_height, kernel_width))

# show results
fig, axs = plt.subplots(2, 2, figsize=(8, 6), layout='constrained')
fig.suptitle('Problem 4 Solution')
axs[0,0].imshow(img_rgb); axs[0,0].set_title('Original')
axs[0,1].imshow(img_median_filter_square)
axs[0,1].set_title(f'{square_kernel:.0f} x {square_kernel:.0f} Kernel')
axs[1,0].imshow(img_median_filter_rect)
axs[1,0].set_title(f'{kernel_height:.0f} x {kernel_width:.0f} Kernel')
axs[1,1].axis('off')
plt.show()
:::

:::{figure} Data/p4_sol.jpg
:align: center
:::

## Problem 5

Using the Haar wavelet, compress the color image by 25% removing only the high/high-pass component.

::::{tip} `compress_image_haar`
:class: dropdown
:::{code} python
def compress_image_haar(image, compression_rate=0.25):
    """
    Compresses a color image using the Haar wavelet by reducing the high/high-pass (HH) 
    component. The function applies the Haar wavelet transform on each color channel (R, G, B) 
    and reduces the HH component by a specified compression rate.

    The function works on color images and applies the Haar wavelet independently to each 
    color channel (Red, Green, Blue).

    Parameters:
    -----------
    image : numpy.ndarray
        The input image as a 3D array. The image must be a color image (BGR format with 3 channels).
    compression_rate : float, optional
        The percentage of the high/high-pass (HH) component to reduce. The default is 0.25 (25% reduction).

    How it works:
    -------------
    - The function first applies a 2D Haar wavelet transform to each of the three color channels (Red, Green, Blue).
    - It then reduces the high-frequency diagonal components (HH subband) by scaling them down based on the 
      provided compression rate.
    - After modifying the HH components, the function reconstructs the image by performing an inverse Haar wavelet 
      transform on each color channel.
    - The result is an image with some loss of high-frequency details, particularly in diagonal areas.

    Compression:
    ------------
    - The HH (high/high-pass) component represents diagonal high-frequency details in the image. Reducing this component 
      compresses the image by removing fine details, resulting in a smoother, compressed image.
    - The compression rate determines how much of the HH component is removed. A compression rate of 0.25 removes 25% of 
      the HH component.

    Example:
    --------
    To compress an image by removing 25% of the HH component:

        compressed_image = compress_image_haar(image, compression_rate=0.25)

    Returns:
    --------
    compressed_image : numpy.ndarray
        The compressed image with the same dimensions as the input image. The image will be color (3 channels).

    Raises:
    -------
    ValueError:
        If the compression rate is not between 0 and 1.
    """

    # Ensure compression rate is valid
    if not (0 < compression_rate < 1):
        raise ValueError("Compression rate must be a float between 0 and 1.")

    # Initialize a list to store the compressed channels
    compressed_channels = []

    # Perform wavelet transform on each color channel (R, G, B)
    for c in range(3):  # Loop through the color channels
        # Apply 2D Haar wavelet transform to the channel
        coeffs = pywt.dwt2(image[:, :, c], 'haar')
        LL, (LH, HL, HH) = coeffs  # LL: low-low, LH: low-high, HL: high-low, HH: high-high

        # Remove a portion of the HH component
        HH *= (1 - compression_rate)

        # Reconstruct the channel using the modified coefficients (with the reduced HH component)
        compressed_channel = pywt.idwt2((LL, (LH, HL, HH)), 'haar')
        compressed_channels.append(compressed_channel)

    # Stack the channels back together and clip to valid pixel range [0, 255]
    compressed_image = np.stack(compressed_channels, axis=-1)
    compressed_image = np.clip(compressed_image, 0, 255).astype(np.uint8)
    
    return compressed_image
:::
::::

:::{code} python
# compress the image
img_compressed = hw.compress_image_haar(img_rgb, compression_rate=0.25)

# get the size of each image
img_rgb_size = img_rgb.size
img_compressed_size = img_compressed.size

# Show the differences in the images
difference = np.abs(img_rgb.astype(np.float32) - img_compressed.astype(np.float32))

# show the image
fig, axs = plt.subplots(2, 2, figsize=(8,6), layout='constrained')
fig.suptitle('Problem 5 Solution')
axs[0,0].imshow(img_rgb); axs[0,0].set_title('Original')
axs[0,1].imshow(img_compressed); axs[0,1].set_title('Compressed')
axs[1,0].imshow(difference / np.max(difference))
axs[1,0].set_title('Difference')
axs[1,1].axis('off')
plt.show()
:::

:::{figure} Data/p5_sol.jpg
:align: center
:::




























































